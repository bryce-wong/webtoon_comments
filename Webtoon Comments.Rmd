---
title: "Webtoon Comments"
author: "Bryce Wong"
date: "January 29, 2019"
output: github_document
---

```{r setup, include=FALSE}
library(rvest)
library(stringr)
library(tidyverse)
library(purrr)
library(here)
```

###Using PhantomJS to scrape Line WEBTOON comments

Reading in comments from the first episode:

Some things to note: 

*Will be following ethical principles as outlined [here]("https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01"").

*Will also be adapting how to scrape a javascript page from R Ladies NYC [here]("http://www.rladiesnyc.org/post/scraping-javascript-websites-in-r/#javascript-webscraping-in-r").

*Finally, I have looked at Webtoon's robots.txt and it looks like I should be able to scrape comments.

```{r javascript code}
# write the javascript code to a new file, scrape.js

writeLines("var url = 'http://example.com';
var webPage = require('webpage');
var page = webPage.create();
var fs = require('fs');

function click(el){
    var ev = document.createEvent('MouseEvent');
    ev.initMouseEvent(
        'click',
        true /* bubble */, true /* cancelable */,
        window, null,
        0, 0, 0, 0, /* coordinates */
        false, false, false, false, /* modifier keys */
        0 /*left*/, null
    );
    el.dispatchEvent(ev);
}

page.open(url, function (status) {
              page.includeJs('http://ajax.googleapis.com/ajax/libs/jquery/1.6.1/jquery.min.js', function(){
                page.evaluate(function(){
                  var replyboxes = document.getElementsByClassName('.u_cbox_btn_reply');
                  for(var i = 0, j = replyboxes.length; i < j; i++){
                    replyboxes[i].click();
                  };
                });
        });
        just_wait();
});

function just_wait() {
    setTimeout(function() {
            fs.write('comments.html', page.content, 'w');
            phantom.exit();
    }, 2500);
}
", con = "scrape.js")
```
        
```{r converting to html}
js_scrape <- function(url, js_path){
  
  # this section will replace the url in scrape.js to whatever you want 
  lines <- readLines(js_path)
  lines[1] <- paste0("var url ='", url ,"';")
  writeLines(lines, js_path)
  
  phantompath = "phantomjs"
  command = paste(phantompath, js_path, sep = " ")
  system(command)

}

js_scrape(url = "https://www.webtoons.com/en/challenge/tested/heck-of-a-start/viewer?title_no=231173&episode_no=1", 
                      js_path = "scrape.js")
```

```{r scrape comments}
# read the newly created html file 
html <- read_html("comments.html")

c <- html %>% 
  html_nodes(".u_cbox_contents") %>%
  html_text()

reviews = tibble(
  comments = c
)
```

###Attempt with RSelenium:

Needed to download JAVA and the chrome webdriver.

```{r starting server}
library(RSelenium)
driver = rsDriver(browser = c("chrome"))
remDr = driver[["client"]]
```

```{r scraping}
remDr$navigate("https://www.webtoons.com/en/challenge/tested/heck-of-a-start/viewer?title_no=231173&episode_no=1")

replies <- remDr$findElement(using = 'css',  "[class = 'u_cbox_contents']")

replies$clickElement()
```

```{r stop server}
remDr$close()
driver$server$stop()
driver$server$process
```




